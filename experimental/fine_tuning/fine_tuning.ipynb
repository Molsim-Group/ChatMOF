{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_files = list(Path('./test/searcher_gpt-4/').glob('*.output'))\n",
    "predictor_files = list(Path('./test/predictor_gpt-4/').glob('*.output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test/searcher2.txt') as f:\n",
    "    search_question = [line.strip() for line in f]\n",
    "\n",
    "with open('test/predictor2.txt') as f:\n",
    "    predict_question = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(logfile):\n",
    "    logfile = regex.sub(r\"\u001b\\[.+?m\", \"\", logfile)\n",
    "    if '########## Output ##############################' not in logfile:\n",
    "        return None\n",
    "    logfile = logfile.split('> Entering new AgentExecutor chain...\\n')[-1]\n",
    "    \n",
    "\n",
    "    logfile = logfile.split('########## Output ##############################')[0].strip()\n",
    "\n",
    "    tab = 0\n",
    "    new_logfile = ''\n",
    "    for line in logfile.split(\"\\n\"):\n",
    "        if line.startswith('> Entering'):\n",
    "            tab += 1\n",
    "        elif line.startswith('> Finished'):\n",
    "            tab -= 1\n",
    "        elif not line.strip():\n",
    "            continue\n",
    "        elif not tab:\n",
    "            new_logfile += line + \"\\n\"\n",
    "\n",
    "    return new_logfile.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You act like a material scientist answering a question. Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "search_csv: A tools that extract accurate properties from a look-up table in the database. To use search_csv, the material must be refcode.The input must be a detailed full sentence to answer the question.\n",
    "predictor: Useful tool to predict material properties using machine learning. More imprecise than the search_csv tool, but can be used universally. You must use predictor before using google_search or wikipedia. The input must be a detailed full sentence to answer the question.\n",
    "generator: The tool to use when you need to create materials with specific properties. `generator` must only be used when the original question wants to generate. input must be provided in the form of a full sentence. \n",
    "visualizer: A tools to visualize the structure. The input must be a detailed full sentence to answer the question.\n",
    "Python_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n",
    "ase_repl: A tools for analyzing materials using the ASE library.It allows you to perform tasks using ASE, such as atom coordinates and cell informationThe input must be a detailed full sentence to answer the question.\n",
    "unit_converter: A tool for converting unit. Ask a question about unit conversion and it will tell you how to convert and what information you need. \n",
    "Calculator: Useful for when you need to answer questions about math.\n",
    "google_search: A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
    "Google Search Results JSON: A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results\n",
    "Wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
    "\n",
    "You must not use tool `generator` when `Question` does not required to generate. \n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [search_csv, predictor, generator, visualizer, Python_REPL, ase_repl, unit_converter, Calculator, google_search, Google Search Results JSON, Wikipedia]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_jsonl(prompt1, prompt2):\n",
    "    system = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt,\n",
    "    }\n",
    "\n",
    "    user = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt1.strip()\n",
    "    }\n",
    "\n",
    "    assistant = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": prompt2.strip()\n",
    "    }\n",
    "    tmp = {}\n",
    "    tmp['messages'] = [system, user, assistant]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n",
      "5\n",
      "7\n",
      "6\n",
      "1\n",
      "9\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "len:  83\n"
     ]
    }
   ],
   "source": [
    "#file_list = predictor_files\n",
    "#question_list = predict_question\n",
    "file_list = search_files\n",
    "question_list = search_question\n",
    "\n",
    "len = 0\n",
    "\n",
    "for file in file_list:\n",
    "    number = int(file.stem.split(\"_\")[0])\n",
    "    with file.open() as f:\n",
    "        logfile = f.read()\n",
    "\n",
    "    new_log = parsing(logfile)\n",
    "    question = question_list[number]\n",
    "\n",
    "    #print (question, number, new_log)\n",
    "    if not new_log:\n",
    "        continue\n",
    "    if number in range(11):  # for test set\n",
    "        print (number)\n",
    "        continue\n",
    "\n",
    "    new_log = f'Question: {question}\\nThought: ' + new_log\n",
    "\n",
    "    split = regex.split(r\"(Observation:\\s?|Thought:\\s?)\", new_log)\n",
    "\n",
    "    for i, s in enumerate(split):\n",
    "        if s.startswith('Thought:'):\n",
    "            prompt1 = \"\".join(split[:i+1])\n",
    "            prompt2 = \"\".join(split[i+1:i+3])\n",
    "\n",
    "            total.append(make_jsonl(prompt1, prompt2))\n",
    "\n",
    "    len += 1\n",
    "\n",
    "print ('len: ', len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('test/searcher_gpt-4/59_.output')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_table(logfile):\n",
    "\n",
    "    logfile = regex.sub(r\"\u001b\\[.+?m\", \"\", logfile)\n",
    "    if '########## Output ##############################' not in logfile:\n",
    "        return None\n",
    "    logfile = logfile.split('> Entering new AgentExecutor chain...\\n')[-1]\n",
    "    \n",
    "    logfile = logfile.split('########## Output ##############################')[0].strip()\n",
    "\n",
    "    tab = 0\n",
    "    new_logfile = ''\n",
    "    for line in logfile.split(\"\\n\"):\n",
    "        if line.startswith('> Entering'):\n",
    "            tab += 1\n",
    "        elif line.startswith('> Finished'):\n",
    "            tab -= 1\n",
    "        elif not line.strip():\n",
    "            continue\n",
    "        elif tab == 1:\n",
    "            new_logfile += line.replace(\"[Table Searcher] \", \"\") + \"\\n\"\n",
    "        elif tab == 0 and line.startswith('Observation'):\n",
    "            new_logfile += line.replace('Observation:', 'Final Answer:')\n",
    "\n",
    "    return new_logfile.strip()\n",
    "\n",
    "    return logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_excel('./database/tables/coremof.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are working with a pandas dataframe in Python. The name of the dataframe is `df`.\n",
    "You should make a valid python command as input. You must use print the output using the `print` function at the end.\n",
    "You should use the `to_markdown` function when you print a pandas object.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Input: the valid python code only using the Pandas library\n",
    "Observation: the result of python code\n",
    "... (this Thought/Input/Observation can repeat N times)\n",
    "Final Thought: you should think about how to answer the question based on your observation\n",
    "Final Answer: the final answer to the original input question. If you can't answer the question, say `nothing`\n",
    "\n",
    "The index of the dataframe must be be one of ['name', 'Largest cavity diameter (Å)', 'Pore limiting diameter (Å)', 'Largest free pore diameter (Å)', 'Density (g/cm^3)', 'Accessible Surface Area (m^2/g)', 'Nonaccessible surface area (m^2/g)', 'Accessible volume volume fraction', 'void fraction', 'Accessible pore volume (cm^3/g)', 'Accessible volume (cm^3/g)', 'Nonaccessible Volume (cm^3/g)', 'Metal type', 'Has open metal site', 'Type of open metal']. If it's not in the index you want, skip straight to Final Thought.\n",
    "\n",
    "Begin!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n",
      "5\n",
      "7\n",
      "6\n",
      "1\n",
      "9\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "Len:  83\n"
     ]
    }
   ],
   "source": [
    "file_list = search_files\n",
    "question_list = search_question\n",
    "\n",
    "len = 0\n",
    "\n",
    "for file in file_list[:]:\n",
    "    number = int(file.stem.split(\"_\")[0])\n",
    "    with file.open() as f:\n",
    "        logfile = f.read()\n",
    "\n",
    "    new_log = parsing_table(logfile)\n",
    "    question = question_list[number]\n",
    "\n",
    "    #print (question, number, new_log)\n",
    "    if not new_log:\n",
    "        continue\n",
    "\n",
    "    if number in range(11):  # for test set\n",
    "        print (number)\n",
    "        continue\n",
    "\n",
    "    new_log = f'Question: {question}\\n' + new_log\n",
    "\n",
    "    split = regex.split(r\"(Observation:\\s?|(?:Final )?Thought:\\s?)\", new_log)\n",
    "\n",
    "    for i, s in enumerate(split):\n",
    "        if s.startswith('Thought:') or s.startswith('Final Thought:'):\n",
    "            prompt1 = \"\".join(split[:i+1])\n",
    "            prompt2 = \"\".join(split[i+1:i+3])\n",
    "\n",
    "            total_table.append(make_jsonl(prompt1, prompt2))\n",
    "\n",
    "    len += 1\n",
    "\n",
    "print ('Len: ', len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Question: Can cg901114e_si_002 have an open metal site?\n",
      "Thought:\n",
      "(!) To find the information about a specific material, we can use the loc function in pandas. This function allows us to access a group of rows and columns by label(s) or a boolean array.\n",
      "Input: print(df.loc[df['name'] == 'cg901114e_si_002'].to_markdown())\n",
      "Observation:\n",
      "\n",
      "\n",
      "\n",
      "(!) Question: Can cg901114e_si_002 have an open metal site?\n",
      "Thought: To find the information about a specific material, we can use the loc function in pandas. This function allows us to access a group of rows and columns by label(s) or a boolean array.\n",
      "Input: print(df.loc[df['name'] == 'cg901114e_si_002'].to_markdown())\n",
      "Observation: \n",
      "|      | name             |   Largest cavity diameter (Å) |   Pore limiting diameter (Å) |   Largest free pore diameter (Å) |   Density (cm^3/g) |   Accessible Surface Area (m^2/cm^3) |   Accessible Surface Area (m^2/g) |   Nonaccessible Surface Area (m^2/cm^3) |   Nonaccessible surface area (m^2/g) |   Accessible volume volume fraction |   void fraction |   Accessible pore volume (cm^3/g) |   Accessible volume (cm^3/g) |   Nonaccessible Volume (cm^3/g) | Metal type   | Has open metal site   | Type of open metal   |\n",
      "|-----:|:-----------------|------------------------------:|-----------------------------:|---------------------------------:|-------------------:|-------------------------------------:|----------------------------------:|----------------------------------------:|-------------------------------------:|------------------------------------:|----------------:|----------------------------------:|-----------------------------:|--------------------------------:|:-------------|:----------------------|:---------------------|\n",
      "| 1178 | cg901114e_si_002 |                       4.97956 |                      4.41476 |                          4.97764 |            1.61977 |                              1113.96 |                           687.724 |                                       0 |                                    0 |                              0.4738 |          0.4738 |                           0.29251 |                      0.29251 |                               0 | Na,Ce        | Yes                   | Na,Ce                |\n",
      "Final Thought:\n",
      "(!) The material 'cg901114e_si_002' does have open metal sites. The type of open metal is Na,Ce.\n",
      "Final Answer: Yes, the material 'cg901114e_si_002' has open metal sites and the type of open metal is Na,Ce.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in total_table:\n",
    "\n",
    "    print ('(!)',i['messages'][1]['content'])\n",
    "    print ('(!)', i['messages'][2]['content'])\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in total:\n",
    "    with open('../experimental/ft_agent/ft_agent.jsonl', 'a') as f:\n",
    "        json.dump(item, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset:  432\n"
     ]
    }
   ],
   "source": [
    "print ('total dataset: ', len(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in total_table:\n",
    "    with open('../experimental/ft_agent/ft_table.jsonl', 'a') as f:\n",
    "        json.dump(item, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset:  182\n"
     ]
    }
   ],
   "source": [
    "print ('total dataset: ', len(total_table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatmof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
